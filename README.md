# ðŸ’³ Credit Risk Escalation System

**An intelligent ML system that automates loan decisions with uncertainty-aware escalation to human reviewers**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ðŸŽ¯ Overview

This system uses **machine learning with uncertainty quantification** to:
- âœ… **Automate 70-85%** of loan decisions with high confidence
- ðŸ”´ **Escalate 15-30%** of uncertain cases to human agents
- ðŸ“Š **Achieve >85%** accuracy on automated decisions
- ðŸ’° **Save ~20%** costs through intelligent automation

### Key Innovation
Unlike traditional ML systems that force predictions on all cases, this system **knows when it doesn't know** and routes uncertain cases to human experts.

---

## âš¡ Quick Start

### For First-Time Setup:

```bash
# 1. Clone repository
git clone https://github.com/Lazy-Loaders-Group/Credit_Risk_Escalation.git
cd Credit_Risk_Escalation

# 2. Run setup script
chmod +x setup.sh
./setup.sh

# 3. Activate environment
source uom_venv/bin/activate  # or .venv/bin/activate

# 4. Start Jupyter
jupyter notebook
```

### To Use Existing Setup:

```bash
# Activate environment
cd Credit_Risk_Escalation
source uom_venv/bin/activate

# Run evaluation notebook
jupyter notebook notebooks/05_comprehensive_evaluation.ipynb
```

---

## ðŸ“Š System Architecture

```
New Loan Application
        â†“
[1] Data Preprocessing
    â€¢ Clean & encode data
    â€¢ Scale features
        â†“
[2] Bootstrap Ensemble (30 models)
    â€¢ Each model votes
    â€¢ Calculate uncertainty from variance
        â†“
[3] Uncertainty Quantification
    â€¢ High disagreement = High uncertainty
    â€¢ Low disagreement = High confidence
        â†“
[4] Escalation Decision
    IF high uncertainty OR low confidence:
        â†’ ðŸ”´ ESCALATE to human
    ELSE:
        â†’ âœ… AUTOMATED decision
        â†“
[5] Output: Decision + Confidence + Explanation
```

---

## ðŸš€ Features

- **Bootstrap Ensemble**: 30-model ensemble for robust predictions
- **Uncertainty Quantification**: Measure prediction uncertainty through model variance
- **Intelligent Escalation**: Automatic routing based on confidence thresholds
- **Cost Optimization**: Balance automation vs. human review costs
- **Full Explainability**: SHAP values for model interpretability
- **Performance Tracking**: Comprehensive metrics and visualizations

---

## ðŸ“ Project Structure

```
Credit_Risk_Escalation/
â”œâ”€â”€ notebooks/                # Jupyter notebooks (main interface)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb
â”‚   â”œâ”€â”€ 03_uncertainty_quantification.ipynb
â”‚   â”œâ”€â”€ 04_escalation_system.ipynb
â”‚   â””â”€â”€ 05_comprehensive_evaluation.ipynb â­
â”‚
â”œâ”€â”€ src/                      # Source code modules
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ uncertainty_quantification.py
â”‚   â””â”€â”€ escalation_system.py
â”‚
â”œâ”€â”€ results/models/           # Trained models (generated)
â”‚   â”œâ”€â”€ preprocessor.pkl
â”‚   â”œâ”€â”€ bootstrap_ensemble.pkl
â”‚   â””â”€â”€ escalation_system.pkl
â”‚
â”œâ”€â”€ data/                     # Data files
â”‚   â”œâ”€â”€ raw/                  # Original dataset
â”‚   â””â”€â”€ splits/               # Train/val/test splits
â”‚
â”œâ”€â”€ predict_new_loan.py       # CLI prediction script (in development)
â”œâ”€â”€ simple_predict.py         # Works with preprocessed data
â”œâ”€â”€ app.py                    # Streamlit web app (in development)
â”œâ”€â”€ setup.sh / setup.bat      # Setup scripts
â””â”€â”€ requirements.txt          # Python dependencies
```

---

## ðŸ“ˆ Performance Metrics

| Metric | Value | Description |
|--------|-------|-------------|
| **Automation Rate** | 70-85% | Decisions handled automatically |
| **Escalation Rate** | 15-30% | Cases needing human review |
| **Automated Accuracy** | >85% | Quality of automated decisions |
| **Cost Savings** | ~20% | Reduction in manual review costs |
| **Models** | 30 | Bootstrap ensemble size |

---

## ðŸŽ“ How It Works

### 1. Uncertainty Quantification

The system uses a **bootstrap ensemble** of 30 models:
- Each model is trained on a different sample of data
- For each prediction, all 30 models vote
- **High agreement** â†’ Low uncertainty â†’ Automate
- **Low agreement** â†’ High uncertainty â†’ Escalate

### 2. Escalation Criteria

A case is escalated if ANY of these apply:
- **High Uncertainty**: `uncertainty > 0.1` (models disagree)
- **Low Confidence**: `confidence < 0.7` (not sure either way)
- **Borderline Probability**: `0.4 < probability < 0.6` (near decision boundary)

### 3. Example Results

**Automated Approval** âœ…
```
Probability of Default: 25%
Confidence: 85%
Uncertainty: 0.03
â†’ AUTOMATED APPROVE (no review needed)
```

**Escalated Case** ðŸ”´
```
Probability of Default: 52%
Confidence: 52%
Uncertainty: 0.15
â†’ ESCALATE TO AGENT (requires human judgment)
```

---

## ðŸ“š Documentation

- **[CURRENT_STATUS.md](CURRENT_STATUS.md)** - What's working now â­ START HERE
- **[SETUP_README.md](SETUP_README.md)** - Complete setup instructions
- **[HOW_TO_USE.md](HOW_TO_USE.md)** - Usage guide
- **[PREDICTION_GUIDE.md](PREDICTION_GUIDE.md)** - Detailed prediction documentation
- **[PROJECT_GUIDE.md](PROJECT_GUIDE.md)** - Full project plan
- **[FINAL_SUMMARY.md](FINAL_SUMMARY.md)** - Implementation summary

---

## ðŸ”§ Prerequisites

- **Python 3.10-3.12** ([Download](https://www.python.org/downloads/))
- **Git** ([Download](https://git-scm.com/downloads/))
- **4GB RAM** (minimum)
- **2GB free disk space**

---

## ðŸ’» Usage

### Primary Method: Jupyter Notebooks (Recommended)

The fully functional system is available through Jupyter notebooks:

```bash
# Activate environment
source uom_venv/bin/activate

# Open Jupyter
jupyter notebook

# Run: notebooks/05_comprehensive_evaluation.ipynb
```

This notebook provides:
- âœ… Complete prediction pipeline
- âœ… Uncertainty quantification
- âœ… Escalation analysis
- âœ… Performance metrics
- âœ… Visual charts
- âœ… Detailed reports

### Alternative: Command Line (For Preprocessed Data)

```bash
# Predict on pre-processed data
python simple_predict.py --input data/splits/X_test.csv --output predictions.csv --limit 1000
```

---

## ðŸ› ï¸ Development Status

### âœ… Completed & Working:
- [x] ML models trained and optimized
- [x] Bootstrap ensemble implementation
- [x] Uncertainty quantification system
- [x] Intelligent escalation logic  
- [x] Performance evaluation
- [x] Visualization and reporting
- [x] Complete documentation
- [x] Setup scripts for any computer

### ðŸ”„ In Development:
- [ ] Standalone preprocessing pipeline
- [ ] Command-line tool for raw data
- [ ] Web application interface

**Note**: Core functionality is complete and working through notebooks!

---

## ðŸ¤ Contributing

This project was developed by the **Lazy Loaders Team** for credit risk assessment research.

To contribute:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ðŸ“„ License

This project is for educational purposes. See LICENSE file for details.

---

## ðŸ†˜ Support

- **Documentation**: Check the `docs/` folder and markdown files
- **Issues**: Open an issue on GitHub
- **Quick Help**: Read [CURRENT_STATUS.md](CURRENT_STATUS.md)

---

## ðŸŽ¯ Use Cases

### Financial Institutions
- Automate routine loan approvals
- Route complex cases to experienced officers
- Reduce processing time and costs

### Risk Management
- Identify high-uncertainty decisions
- Maintain human oversight on edge cases
- Improve decision quality

### Research & Education
- Study uncertainty quantification methods
- Learn production ML system design
- Explore cost-benefit optimization

---

## ðŸ† Key Results

From actual training on Lending Club dataset:

- **210,000+ loans** analyzed
- **78% automation rate** achieved
- **89% accuracy** on automated decisions
- **$678 savings** demonstrated per batch
- **21% cost reduction** in total review process

---

## ðŸ“ž Contact

- **Repository**: https://github.com/Lazy-Loaders-Group/Credit_Risk_Escalation
- **Team**: Lazy Loaders
- **Email**: [Contact maintainers]

---

## ðŸ™ Acknowledgments

- **Dataset**: Lending Club Loan Data
- **Libraries**: scikit-learn, XGBoost, pandas, numpy
- **Visualization**: matplotlib, seaborn, plotly
- **Notebooks**: Jupyter

---

## ðŸš€ Get Started Now

```bash
# Quick start (3 commands)
git clone https://github.com/Lazy-Loaders-Group/Credit_Risk_Escalation.git
cd Credit_Risk_Escalation
./setup.sh && source uom_venv/bin/activate && jupyter notebook
```

Then open: `notebooks/05_comprehensive_evaluation.ipynb`

---

**Last Updated**: November 22, 2024  
**Version**: 1.0.0  
**Status**: âœ… Production Ready (via Jupyter notebooks)

---

**â­ Star this repo if you find it useful!**

**ðŸ“– Read [CURRENT_STATUS.md](CURRENT_STATUS.md) to see what's working now.**
